{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load docs, queries and the inverted index\n",
    "with open(\"./Output/preprocessed_docs\",\"rb\") as file:\n",
    "    docs = pickle.load(file)\n",
    "\n",
    "with open(\"./Output/preprocessed_queries\",\"rb\") as file:\n",
    "    queries = pickle.load(file)\n",
    "\n",
    "with open(\"./Output/inverted_index\",\"r\") as file:\n",
    "    inverted_index = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_weights1(tf,idf,term):\n",
    "    return (0.5 + (0.5*tf[term])/tf[max(tf)]) * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_weights2(tf,idf,term):\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_weights1(tf,idf,term):\n",
    "    return tf*idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_space(query,docs, query_weight_func, doc_weight_func):\n",
    "\n",
    "        tf={}\n",
    "        \n",
    "        for term in set(query):#Get query term frequency\n",
    "                tf[term] = query.count(term)\n",
    "\n",
    "        #Calculate query and doc weights\n",
    "        query_weights = []\n",
    "        document_weights = {}\n",
    "\n",
    "        for doc in docs:\n",
    "                document_weights[doc[0]] = []\n",
    "        \n",
    "        for term in set(query):\n",
    "\n",
    "               # if  len(inverted_index[term]):\n",
    "                if term in inverted_index and len(inverted_index[term]):\n",
    "                        \n",
    "                        idf = math.log(len(docs)/len(inverted_index[term]))\n",
    "\n",
    "                        query_weights.append(query_weight_func(tf,idf,term))\n",
    "\n",
    "                        for doc in docs:\n",
    "\n",
    "                                try:\n",
    "                                        tf_doc = inverted_index[term][doc[0]]\n",
    "                                except:\n",
    "                                        tf_doc = 0\n",
    "\n",
    "                                w = doc_weight_func(tf_doc,idf,term)\n",
    "                                document_weights[doc[0]].append(w)   \n",
    "\n",
    "       \n",
    "        #Calcualte cosine similarity for each doc\n",
    "        sim = {}\n",
    "        for doc in document_weights:\n",
    "                sim[doc] = cosine_similarity([query_weights],[document_weights[doc]])\n",
    "\n",
    "        return sorted(sim.items(), key=lambda x:x[1])[-500:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[798, 796, 596, 991, 330, 909, 649, 423, 1000, 1119, 333, 1226, 186, 473, 908, 258, 659, 834, 550, 322, 968, 301, 801, 671, 518, 396, 788, 96, 799, 875, 900, 1002, 775, 812, 1064, 99, 429, 712, 661, 175, 319, 483, 835, 1174, 353, 871, 33, 831, 930, 697, 818, 1182, 225, 158, 1014, 849, 318, 946, 870, 644, 378, 35, 877, 470, 36, 234, 1178, 1176, 600, 280, 1028, 403, 482, 38, 71, 772, 784, 791, 335, 272, 643, 943, 370, 684, 1051, 298, 255, 72, 10, 768, 566, 12, 969, 148, 545, 16, 858, 252, 1113, 232, 719, 360, 1158, 215, 310, 1216, 601, 56, 694, 641, 205, 836, 779, 421, 117, 603, 994, 1079, 97, 14, 959, 1031, 1194, 1105, 42, 961, 645, 622, 1127, 374, 667, 230, 564, 498, 680, 164, 249, 522, 847, 415, 337, 853, 288, 960, 455, 951, 358, 141, 1116, 102, 253, 621, 1090, 905, 1162, 887, 625, 1131, 679, 914, 978, 738, 852, 732, 1171, 1132, 263, 1159, 746, 828, 702, 1121, 26, 749, 1029, 369, 528, 840, 631, 546, 285, 841, 145, 904, 874, 23, 658, 633, 428, 1100, 495, 167, 136, 953, 1120, 534, 485, 292, 635, 754, 830, 62, 1209, 629, 1231, 228, 956, 306, 375, 681, 1143, 655, 242, 726, 769, 692, 216, 572, 1142, 218, 313, 18, 653, 1003, 371, 963, 115, 214, 133, 1053, 453, 424, 194, 1059, 710, 1165, 28, 827, 532, 792, 1195, 539, 624, 632, 786, 1099, 725, 366, 447, 246, 1025, 341, 577, 172, 154, 750, 1227, 1202, 1238, 707, 317, 53, 283, 1139, 348, 1060, 357, 118, 4, 935, 1044, 535, 185, 588, 151, 716, 896, 567, 541, 261, 1117, 873, 780, 134, 173, 105, 434, 851, 1237, 139, 554, 553, 401, 548, 1170, 77, 312, 805, 1200, 442, 119, 683, 1157, 176, 931, 741, 54, 1204, 121, 807, 224, 1010, 1086, 1055, 425, 268, 638, 763, 1181, 529, 607, 1201, 19, 192, 377, 989, 160, 137, 571, 743, 63, 278, 1016, 740, 231, 1156, 52, 1222, 43, 297, 766, 437, 988, 49, 277, 530, 217, 384, 803, 586, 80, 409, 1137, 589, 68, 850, 1149, 842, 347, 958, 138, 445, 452, 578, 65, 523, 1006, 1198, 439, 259, 1206, 575, 1030, 986, 765, 85, 737, 647, 191, 417, 941, 161, 1205, 241, 745, 201, 895, 1136, 106, 715, 307, 771, 976, 866, 308, 107, 336, 1167, 147, 981, 515, 1078, 1239, 563, 244, 356, 346, 777, 620, 576, 800, 795, 689, 525, 269, 399, 526, 886, 1130, 124, 1050, 767, 996, 29, 211, 793, 389, 785, 705, 861, 488, 316, 449, 511, 762, 747, 876, 206, 323, 1146, 279, 467, 1026, 11, 240, 748, 665, 112, 630, 196, 466, 901, 304, 294, 55, 728, 110, 734, 350, 431, 362, 325, 652, 340, 551, 361, 1129, 1008, 865, 637, 856, 338, 1169, 1085, 815, 1186, 245, 276, 560, 1093, 142, 79, 778, 1043, 108, 1128, 1235, 1230, 1017, 143, 204, 593, 114, 440, 1133, 898, 222, 456, 1173, 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "\n",
    "# Iterate over queries\n",
    "for query in queries:\n",
    "    # Call the vector_space function and get the result\n",
    "    result = vector_space(query, docs, query_weights1, document_weights1)\n",
    "    \n",
    "    # Extract the second element of each tuple in the result and convert it to a list\n",
    "    elements = [int(item[0]) for item in result]\n",
    "    \n",
    "    # Add the iteration number and the list of second elements to the result_dict\n",
    "\n",
    "    results.append(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Output/vsm_results_1\", \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# Iterate over queries\n",
    "for query in queries:\n",
    "    # Call the vector_space function and get the result\n",
    "    result = vector_space(query, docs, query_weights1, document_weights2)\n",
    "    \n",
    "    # Extract the second element of each tuple in the result and convert it to a list\n",
    "    elements = [int(item[0]) for item in result]\n",
    "    \n",
    "    # Add the iteration number and the list of second elements to the result_dict\n",
    "\n",
    "    results.append(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Output/vsm_results_2\", \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
